{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90f667f3",
   "metadata": {},
   "source": [
    "# Loading Data and Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f650189",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T10:28:56.838535Z",
     "start_time": "2023-06-30T10:28:48.301535Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791d8847",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T10:28:58.206208Z",
     "start_time": "2023-06-30T10:28:58.203595Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.width', 300)\n",
    "pd.set_option('display.max_colwidth', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddddf792",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T10:29:00.344923Z",
     "start_time": "2023-06-30T10:29:00.100704Z"
    }
   },
   "outputs": [],
   "source": [
    "agnews_train = pd.read_csv(\"./agnews/agnews_train.csv\")\n",
    "agnews_test = pd.read_csv(\"./agnews/agnews_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aeb9a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T10:29:01.452701Z",
     "start_time": "2023-06-30T10:29:01.431628Z"
    }
   },
   "outputs": [],
   "source": [
    "agnews_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f9dca1",
   "metadata": {},
   "source": [
    "The labels are evenly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb27730a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T10:29:03.058861Z",
     "start_time": "2023-06-30T10:29:02.988249Z"
    }
   },
   "outputs": [],
   "source": [
    "duplicates_train = agnews_train.duplicated().sum()\n",
    "duplicates_test = agnews_test.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3917cb4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T10:29:03.606263Z",
     "start_time": "2023-06-30T10:29:03.603146Z"
    }
   },
   "outputs": [],
   "source": [
    "f'train dataset has {duplicates_train} amount of duplicates, while test dataset has {duplicates_test} amount of duplicates.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c3a095",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T10:29:04.279436Z",
     "start_time": "2023-06-30T10:29:04.200811Z"
    }
   },
   "outputs": [],
   "source": [
    "agnews_train = agnews_train.drop_duplicates()\n",
    "\n",
    "agnews_test = agnews_test.drop_duplicates()\n",
    "\n",
    "label_mapping = {\n",
    "    0: \"Science\",\n",
    "    1: \"Sports\",\n",
    "    2: \"World\",\n",
    "    3: \"Business\"\n",
    "}\n",
    "\n",
    "agnews_train['label_int'] = agnews_train['label_int'].map(label_mapping)\n",
    "agnews_test['label_int'] = agnews_test['label_int'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab703967",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T10:29:05.801927Z",
     "start_time": "2023-06-30T10:29:05.785601Z"
    }
   },
   "outputs": [],
   "source": [
    "agnews_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77bdc8b",
   "metadata": {},
   "source": [
    "# Explaining the dataset and what were doing\n",
    "\n",
    "The dataset contains information regarding whether a text from a news agency is in the science section, sports section, world news section or business news section. So, the data is divided into \"text\" which is the text were trying to classify as well as a marker telling us which of the 4 it pertains to. What were trying to do is 2 main things.\n",
    "\n",
    "1. Create models that can correctly classify between a given text news section and all other (0,1) which is binary classification. (can we say that a text is from the sports section or business section etc) (the models will say \"business or not business, thus the 0,1).\n",
    "2. Create models that can correctly classify between any of the 4 sections (0,1,2,3) which is multi-class classification. Here the models will choose one out of the 4 sections.\n",
    "3. Create learning curves that tell us several things.\n",
    "    1. How much does the training data size affect the performance of our model, does it scale linearly, does it plateau, do we need all the data or only part of it to get the highest score etc.\n",
    "    2. How long does it take to train a model with different training data sizes, is it linear? does it increase exponentially?\n",
    "    3. How well does the performance of the models scale with the computational time? Do we care about an extra 0.1% recall if it costs us 500 seconds more to run a model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c64070f",
   "metadata": {},
   "source": [
    "# Binary Classification Methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2224d82c",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208835fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T21:14:17.137543Z",
     "start_time": "2023-06-18T21:11:49.207352Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "def train_NB_classifier(label, vectorizer_type, ngram):\n",
    "   \n",
    "    X_train = agnews_train['text']\n",
    "    y_train = agnews_train[label]\n",
    "    X_test = agnews_test['text']\n",
    "    y_test = agnews_test[label]\n",
    "    \n",
    "    \n",
    "    if vectorizer_type == 'CountVectorizer':\n",
    "        vectorizer = CountVectorizer(ngram_range=(1,ngram))\n",
    "    elif vectorizer_type == 'TfidfVectorizer':\n",
    "        vectorizer = TfidfVectorizer(ngram_range=(1,ngram))\n",
    "        \n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    \n",
    "    \n",
    "    model = MultinomialNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "   \n",
    "    predictions = model.predict(X_test)\n",
    "    print(f\"Classification Report for {label} with Naive Bayes, {vectorizer_type} and ngram=(1,{ngram}):\")\n",
    "    print(metrics.classification_report(y_test, predictions))\n",
    "    \n",
    "for label in ['science_int', 'sports_int', 'world_int', 'business_int']:\n",
    "    for vectorizer_type in ['CountVectorizer', 'TfidfVectorizer']:\n",
    "        for ngram in [1,2,3]:\n",
    "            train_NB_classifier(label, vectorizer_type, ngram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4754d7",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63711964",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T12:45:40.849147Z",
     "start_time": "2023-06-18T12:38:12.548489Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def train_LR_classifier(label, vectorizer_type, ngram):\n",
    "    \n",
    "    X_train = agnews_train['text']\n",
    "    y_train = agnews_train[label]\n",
    "    X_test = agnews_test['text']\n",
    "    y_test = agnews_test[label]\n",
    "    \n",
    "    \n",
    "    if vectorizer_type == 'CountVectorizer':\n",
    "        vectorizer = CountVectorizer(ngram_range=(1,ngram))\n",
    "    elif vectorizer_type == 'TfidfVectorizer':\n",
    "        vectorizer = TfidfVectorizer(ngram_range=(1,ngram))\n",
    "        \n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    \n",
    "    \n",
    "    model = LogisticRegression(n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    print(f\"Classification Report for {label} with Logistic Regression, {vectorizer_type} and ngram=(1,{ngram}):\")\n",
    "    print(metrics.classification_report(y_test, predictions))\n",
    "\n",
    "\n",
    "for label in ['science_int', 'sports_int', 'world_int', 'business_int']:\n",
    "    for vectorizer_type in ['CountVectorizer', 'TfidfVectorizer']:\n",
    "        for ngram in [1,2,3]:\n",
    "            train_LR_classifier(label, vectorizer_type, ngram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5462faf",
   "metadata": {},
   "source": [
    "## LinearSVC Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ae564f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T12:50:31.477346Z",
     "start_time": "2023-06-18T12:45:51.261131Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def train_SVC_classifier(label, vectorizer_type, ngram):\n",
    "\n",
    "    X_train = agnews_train['text']\n",
    "    y_train = agnews_train[label]\n",
    "    X_test = agnews_test['text']\n",
    "    y_test = agnews_test[label]\n",
    "    \n",
    "    if vectorizer_type == 'CountVectorizer':\n",
    "        vectorizer = CountVectorizer(ngram_range=(1,ngram))\n",
    "    elif vectorizer_type == 'TfidfVectorizer':\n",
    "        vectorizer = TfidfVectorizer(ngram_range=(1,ngram))\n",
    "        \n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    \n",
    "    model = LinearSVC()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    print(f\"Classification Report for {label} with Linear SVC, {vectorizer_type} and ngram=(1,{ngram}):\")\n",
    "    print(metrics.classification_report(y_test, predictions))\n",
    "\n",
    "for label in ['science_int', 'sports_int', 'world_int', 'business_int']:\n",
    "    for vectorizer_type in ['CountVectorizer', 'TfidfVectorizer']:\n",
    "        for ngram in [1,2,3]:\n",
    "            train_SVC_classifier(label, vectorizer_type, ngram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45014bd6",
   "metadata": {},
   "source": [
    "## Checking the best combination of model, ngram and vectorizer for binary classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb96a6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-17T19:02:52.080127Z",
     "start_time": "2023-06-17T18:57:42.804921Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Initialize a dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# The models we are going to use\n",
    "models = [LinearSVC()]\n",
    "\n",
    "# Train and evaluate the model\n",
    "def train_classifier(label, model, vectorizer_type, ngram):\n",
    "    # Separate features and target\n",
    "    X_train = agnews_train['text']\n",
    "    y_train = agnews_train[label]\n",
    "    X_test = agnews_test['text']\n",
    "    y_test = agnews_test[label]\n",
    "\n",
    "    # Vectorize the text\n",
    "    if vectorizer_type == 'CountVectorizer':\n",
    "        vectorizer = CountVectorizer(ngram_range=(1,ngram))\n",
    "    elif vectorizer_type == 'TfidfVectorizer':\n",
    "        vectorizer = TfidfVectorizer(ngram_range=(1,ngram))\n",
    "\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions, zero_division=1, average='weighted')\n",
    "    recall = recall_score(y_test, predictions, zero_division=1, average='weighted')\n",
    "    f1 = f1_score(y_test, predictions, zero_division=1, average='weighted')\n",
    "\n",
    "    # Store the results\n",
    "    results[label, model.__class__.__name__, vectorizer_type, ngram] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "# Function to get the best model for a given metric and label\n",
    "def get_best_model(metric, label):\n",
    "    # Filter the results for the specific label\n",
    "    filtered_results = {k: v for k, v in results.items() if k[0] == label}\n",
    "    \n",
    "    # Find the model with the highest score for the given metric\n",
    "    best_model = max(filtered_results.items(), key=lambda x: x[1][metric])\n",
    "    print(f\"The best model for metric {metric} and label {label} is: {best_model}\")\n",
    "\n",
    "# Train and evaluate a model for each label, model, vectorizer and ngram\n",
    "for label in ['science_int', 'sports_int', 'world_int', 'business_int']:\n",
    "    for model in models:\n",
    "        for vectorizer_type in ['CountVectorizer', 'TfidfVectorizer']:\n",
    "            for ngram in [1,2,3]:\n",
    "                train_classifier(label, model, vectorizer_type, ngram)\n",
    "\n",
    "# Get the best model for a given metric and label\n",
    "for label in ['science_int', 'sports_int', 'world_int', 'business_int']:\n",
    "    get_best_model('f1', label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a696675c",
   "metadata": {},
   "source": [
    "# Top Features of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5384b81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T21:21:26.167639Z",
     "start_time": "2023-06-18T21:19:52.889801Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "# Setup data\n",
    "X_train = agnews_train['text']\n",
    "y_train = agnews_train['label_int']\n",
    "X_test = agnews_test['text']\n",
    "y_test = agnews_test['label_int']\n",
    "\n",
    "# Use your desired vectorizer (Here I use TfidfVectorizer as an example)\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2)) # Use ngram_range=(1,2) for bigrams\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Linear SVC\": LinearSVC(max_iter=1000)\n",
    "}\n",
    "\n",
    "# Train each model and display results\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    print(f\"Classification Report for {model_name}:\")\n",
    "    print(metrics.classification_report(y_test, predictions))\n",
    "\n",
    "    # Print top N important features for each class if the model has a `feature_log_prob_` attribute (e.g., Naive Bayes)\n",
    "    if hasattr(model, 'feature_log_prob_'):\n",
    "        N = 10\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        for i, class_label in enumerate(model.classes_):\n",
    "            topn_class_indices = np.argsort(model.feature_log_prob_[i])[::-1][:N]\n",
    "            topn_class_features = feature_names[topn_class_indices]\n",
    "            topn_class_logprobs = model.feature_log_prob_[i, topn_class_indices]\n",
    "            print(f\"Top {N} important features for class {class_label}:\")\n",
    "            for feature, log_prob in zip(topn_class_features, topn_class_logprobs):\n",
    "                print(f\"{feature}: {np.exp(log_prob)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123ff088",
   "metadata": {},
   "source": [
    "# Multiclass Classification Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcff4a6e",
   "metadata": {},
   "source": [
    "## What do the class numbers mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092779f0",
   "metadata": {},
   "source": [
    "The results of the model will show performance across 0, 1, 2, and 3. These are the numbers within the column \"label_int\" which tells us the location (:3) of the labels. These are the numbers given to each class.\n",
    "\n",
    "- 0 = science_int\n",
    "- 1 = sports_int\n",
    "- 2 = world_int\n",
    "- 3 = business_int\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d2433c",
   "metadata": {},
   "source": [
    "## Naive Bayes Multiclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2901b949",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T07:09:45.772457Z",
     "start_time": "2023-06-27T07:08:51.457511Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "def train_NB_classifier(vectorizer_type, ngram):\n",
    "    X_train = agnews_train['text']\n",
    "    y_train = agnews_train['label_int']\n",
    "    X_test = agnews_test['text']\n",
    "    y_test = agnews_test['label_int']\n",
    "    \n",
    "    if vectorizer_type == 'CountVectorizer':\n",
    "        vectorizer = CountVectorizer(ngram_range=(1,ngram))\n",
    "    elif vectorizer_type == 'TfidfVectorizer':\n",
    "        vectorizer = TfidfVectorizer(ngram_range=(1,ngram))\n",
    "        \n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    \n",
    "    model = MultinomialNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    print(f\"Classification Report for multiclass with Naive Bayes, {vectorizer_type} and ngram=(1,{ngram}):\")\n",
    "    print(metrics.classification_report(y_test, predictions))\n",
    "\n",
    "for vectorizer_type in ['CountVectorizer', 'TfidfVectorizer']:\n",
    "    for ngram in [1,2,3]:\n",
    "        train_NB_classifier(vectorizer_type, ngram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8197b268",
   "metadata": {},
   "source": [
    "## Logistic Regression MultiClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138aec12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T07:17:22.123831Z",
     "start_time": "2023-06-27T07:10:06.354242Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "def train_LR_classifier(vectorizer_type, ngram):\n",
    "    # Separate features and target\n",
    "    X_train = agnews_train['text']\n",
    "    y_train = agnews_train['label_int']\n",
    "    X_test = agnews_test['text']\n",
    "    y_test = agnews_test['label_int']\n",
    "    \n",
    "    # Vectorize the text\n",
    "    if vectorizer_type == 'CountVectorizer':\n",
    "        vectorizer = CountVectorizer(ngram_range=(1,ngram))\n",
    "    elif vectorizer_type == 'TfidfVectorizer':\n",
    "        vectorizer = TfidfVectorizer(ngram_range=(1,ngram))\n",
    "        \n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    \n",
    "    \n",
    "    model = LogisticRegression(n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    print(f\"Classification Report for multiclass with Logistic Regression, {vectorizer_type} and ngram=(1,{ngram}):\")\n",
    "    print(metrics.classification_report(y_test, predictions))\n",
    "\n",
    "for vectorizer_type in ['CountVectorizer', 'TfidfVectorizer']:\n",
    "    for ngram in [1,2,3]:\n",
    "        train_LR_classifier(vectorizer_type, ngram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08fd3ea",
   "metadata": {},
   "source": [
    "## LinearSVC Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabd7cb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T08:04:34.800070Z",
     "start_time": "2023-06-27T08:00:06.374833Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "def train_L_SVC_classifier(vectorizer_type, ngram):\n",
    "    # Separate features and target\n",
    "    X_train = agnews_train['text']\n",
    "    y_train = agnews_train['label_int']\n",
    "    X_test = agnews_test['text']\n",
    "    y_test = agnews_test['label_int']\n",
    "    \n",
    "    # Vectorize the text\n",
    "    if vectorizer_type == 'CountVectorizer':\n",
    "        vectorizer = CountVectorizer(ngram_range=(1,ngram))\n",
    "    elif vectorizer_type == 'TfidfVectorizer':\n",
    "        vectorizer = TfidfVectorizer(ngram_range=(1,ngram))\n",
    "        \n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    \n",
    "    # Train the model\n",
    "    model = LinearSVC()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    predictions = model.predict(X_test)\n",
    "    print(f\"Classification Report for multiclass with Linear SVC, {vectorizer_type} and ngram=(1,{ngram}):\")\n",
    "    print(metrics.classification_report(y_test, predictions))\n",
    "\n",
    "for vectorizer_type in ['CountVectorizer', 'TfidfVectorizer']:\n",
    "    for ngram in [1,2,3]:\n",
    "        train_L_SVC_classifier(vectorizer_type, ngram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508a253c",
   "metadata": {},
   "source": [
    "# Learning Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154e7c24",
   "metadata": {},
   "source": [
    "## Defining our learning curve plotting function.\n",
    "\n",
    "**Important** If we want to change the amount of training sizes (by how much we divide the total dataset to create steps of training data, we must change the value in bold. \"train_sizes = np.linspace(1, max_train_samples, **25**).astype(int)\"\n",
    "\n",
    "This value is dividing the total dataset by 25, which gives us 25 plotted points or 25 datasets to train on. If we choose 100, computational time will increase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc67eb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T10:17:30.372705Z",
     "start_time": "2023-06-19T10:17:30.359050Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=None):\n",
    "    if axes is None:\n",
    "        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "    axes[0].set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes[0].set_ylim(*ylim)\n",
    "    axes[0].set_xlabel(\"Training examples\")\n",
    "    axes[0].set_ylabel(\"Score\")\n",
    "    \n",
    "    max_train_samples = int(0.8*X.shape[0])  # 80% of the total number of samples\n",
    "    \n",
    "    if train_sizes is None:\n",
    "        max_train_samples = int((1 - 1/cv)*X.shape[0])\n",
    "        train_sizes = np.linspace(1, max_train_samples, 25).astype(int) #As stated above, 25 is the number we divide max train samples by.\n",
    "    elif len(train_sizes) == 0:\n",
    "        raise ValueError(\"train_sizes should not be empty.\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
    "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "                       train_sizes=train_sizes,\n",
    "                       return_times=True)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes[0].grid()\n",
    "    axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "    axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                         color=\"g\")\n",
    "    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Cross-validation score\")\n",
    "    axes[0].legend(loc=\"best\")\n",
    "\n",
    "    # Plot n_samples vs fit_times\n",
    "    axes[1].grid()\n",
    "    axes[1].plot(train_sizes, fit_times_mean, 'o-')\n",
    "    axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,\n",
    "                         fit_times_mean + fit_times_std, alpha=0.1)\n",
    "    axes[1].set_xlabel(\"Training examples\")\n",
    "    axes[1].set_ylabel(\"fit_times\")\n",
    "    axes[1].set_title(\"Scalability of the model\")\n",
    "\n",
    "    # Plot fit_time vs score\n",
    "    axes[2].grid()\n",
    "    axes[2].plot(fit_times_mean, test_scores_mean, 'o-')\n",
    "    axes[2].fill_between(fit_times_mean, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1)\n",
    "    axes[2].set_xlabel(\"fit_times\")\n",
    "    axes[2].set_ylabel(\"Score\")\n",
    "    axes[2].set_title(\"Performance of the model\")\n",
    "\n",
    "    # Save plot as PNG\n",
    "    plt.savefig(f'Learning_Curve_Plot for a {estimator.__class__.__name__} with cv = {cv} and Vectorizer {vectorizer.__class__.__name__}.png')\n",
    "    \n",
    "    return plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a776a3",
   "metadata": {},
   "source": [
    "## Lets vectorize with Tfidf and Ngram range = 1,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7998a22d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T09:32:53.016022Z",
     "start_time": "2023-06-19T09:32:51.267054Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "X = agnews_train['text']\n",
    "y = agnews_train['label_int']\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,1))\n",
    "\n",
    "X = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aac0cab",
   "metadata": {},
   "source": [
    "## Lets plot the learning curves with this vectorizer\n",
    "\n",
    "**Logistic Regression** can take a long time to compute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e831c3",
   "metadata": {},
   "source": [
    "## Naive Bayes Learning Curve ngram (1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc8a40d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T09:33:00.223167Z",
     "start_time": "2023-06-19T09:32:58.508006Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_clf = MultinomialNB()\n",
    "plot_learning_curve(nb_clf, \"Learning curve (Naive Bayes)\", X, y, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68bc9fd",
   "metadata": {},
   "source": [
    "## Logistic Regression Learning Curve ngram (1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eab087",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T09:37:06.800363Z",
     "start_time": "2023-06-19T09:33:05.752084Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression(max_iter=1000)\n",
    "plot_learning_curve(lr_clf, \"Learning curve (Logistic Regression)\", X, y, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a10fde",
   "metadata": {},
   "source": [
    "## Linear SVC Learning Curve ngram (1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6674656c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T09:56:16.192607Z",
     "start_time": "2023-06-19T09:55:52.685786Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "# Linear SVC\n",
    "SVC = LinearSVC()\n",
    "plot_learning_curve(SVC, \"Learning curve (Linear SVC)\", X, y, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3f789c",
   "metadata": {},
   "source": [
    "## Lets vectorize with Tfidf and Ngram range = 1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc503ed8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T10:17:39.262678Z",
     "start_time": "2023-06-19T10:17:34.232573Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Prepare the data\n",
    "X = agnews_train['text']\n",
    "y = agnews_train['label_int']\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "\n",
    "X = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd815f58",
   "metadata": {},
   "source": [
    "## Lets plot the learning curves with this vectorizer\n",
    "\n",
    "**Logistic Regression** can take a long time to compute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fab9bf3",
   "metadata": {},
   "source": [
    "## Naive Bayes Learning Curve ngram (1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54088ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T10:01:34.532695Z",
     "start_time": "2023-06-19T10:01:27.289745Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# Naive Bayes\n",
    "nb_clf = MultinomialNB()\n",
    "plot_learning_curve(nb_clf, \"Learning curve (Naive Bayes)\", X, y, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5664082",
   "metadata": {},
   "source": [
    "## Logistic Regression Learning Curve ngram (1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cef99b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-19T10:17:41.203Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Logistic Regression\n",
    "lr_clf = LogisticRegression(max_iter=1000,n_jobs=-1)\n",
    "plot_learning_curve(lr_clf, \"Learning curve (Logistic Regression)\", X, y, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c1ec56",
   "metadata": {},
   "source": [
    "## Linear SVC Learning Curve ngram (1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01619903",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T10:03:08.478609Z",
     "start_time": "2023-06-19T10:01:49.533492Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "# Linear SVC\n",
    "SVC = LinearSVC()\n",
    "plot_learning_curve(SVC, \"Learning curve (Linear SVC)\", X, y, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5365b5fe",
   "metadata": {},
   "source": [
    "# Some conclusion from the mandatory goals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efe9c48",
   "metadata": {},
   "source": [
    "So we see that a more complex model such as a logistic regression does't actually increase our performance metrics. A linear SVC for this simple dataset is more than enough. We also see that including unigrams and bigrams is what gives us the best performance with the inclusion of trigrams, some loss of performance is seen.\n",
    "\n",
    "Adding on, the dataset is very large and we can clearly see that we don't need all of the data to get good performance levels. The main idea to take away from this analysis is \"Is a more complex model always better? Answer is no, and \"Is more data always better\" answer is also no, we want enough data to make correct predictions, but not too much that our models are very hard to train."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bfeaf7",
   "metadata": {},
   "source": [
    "# Optional Goal 1 - Tuning classifiers for High Recall and High Precision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06c5853",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T07:03:26.249618Z",
     "start_time": "2023-06-27T07:03:09.027001Z"
    }
   },
   "source": [
    "Our model chosen will be the a logistic regression, TfidfVectorizer and ngram=(1,2) in multiclass classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02332a93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-30T10:39:45.572059Z",
     "start_time": "2023-06-30T10:36:26.512504Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, precision_recall_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the model and vectorizer\n",
    "lg = LogisticRegression(max_iter=1000,n_jobs=-1)\n",
    "clf = CalibratedClassifierCV(lg) \n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2)) # using both unigrams and bigrams\n",
    "\n",
    "colors = ['b', 'g', 'r', 'c'] #styling the graphs this is purely cosmetic.\n",
    "\n",
    "for color, label in zip(colors, ['science_int', 'sports_int', 'world_int', 'business_int']):\n",
    "    # Prepare the data\n",
    "    X_train = agnews_train['text']\n",
    "    y_train = agnews_train[label]\n",
    "    X_test = agnews_test['text']\n",
    "    y_test = agnews_test[label]\n",
    "\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "\n",
    "    # Train the model\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Get the predicted probabilities\n",
    "    y_train_proba = clf.predict_proba(X_train)[:, 1]\n",
    "    y_test_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Precision-Recall curve, we use the sk learn implementation\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_test_proba)\n",
    "\n",
    "    # High precision classifier\n",
    "    high_precision_threshold = thresholds[np.argmax(precision)]\n",
    "    y_test_pred_high_precision = (y_test_proba >= high_precision_threshold).astype(int)\n",
    "\n",
    "    # High recall classifier\n",
    "    high_recall_threshold = thresholds[np.argmax(recall)]\n",
    "    y_test_pred_high_recall = (y_test_proba >= high_recall_threshold).astype(int)\n",
    "\n",
    "    # Plotting Precision-Recall curve\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(recall, precision, color=color, label='Precision-Recall curve')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall trade-off for {label}')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'{label}.png')  # Save the figure\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\nTest Classification Report for High Precision Classifier ({label}):\")\n",
    "    print(f\"High precision threshold: {high_precision_threshold}\")\n",
    "    print(classification_report(y_test, y_test_pred_high_precision))\n",
    "\n",
    "    print(f\"\\nTest Classification Report for High Recall Classifier ({label}):\")\n",
    "    print(f\"High recall threshold: {high_recall_threshold}\")\n",
    "    print(classification_report(y_test, y_test_pred_high_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168d65fa",
   "metadata": {},
   "source": [
    "# Optional Goal 2 - How does our model perform with newer datasets?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a47199",
   "metadata": {},
   "source": [
    "First, we check that in fact this new AGnews dataset is not the same as the one we have. This comes from kaggle and its supposed to be real but we never know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d03bc9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T20:10:16.776223Z",
     "start_time": "2023-06-27T20:10:16.483977Z"
    }
   },
   "outputs": [],
   "source": [
    "new_dataset_test = pd.read_csv(\"./agnews/new dataset/test.csv\")\n",
    "new_dataset_train = pd.read_csv(\"./agnews/new dataset/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ee8d0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T20:10:22.418721Z",
     "start_time": "2023-06-27T20:10:22.415681Z"
    }
   },
   "outputs": [],
   "source": [
    "is_equal = agnews_test.equals(new_dataset_test)\n",
    "is_equal_train = agnews_train.equals(new_dataset_train)\n",
    "\n",
    "print(\"Are the dataframes equal?\", is_equal)\n",
    "print(\"Are the dataframes equal?\", is_equal_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4253df92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T20:10:24.271552Z",
     "start_time": "2023-06-27T20:10:24.148233Z"
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate the two test datasets and check for duplicates\n",
    "test_data_combined = pd.concat([agnews_test, new_dataset_test])\n",
    "duplicates_test = test_data_combined.duplicated()\n",
    "\n",
    "# Concatenate the two train datasets and check for duplicates\n",
    "train_data_combined = pd.concat([agnews_train, new_dataset_train])\n",
    "duplicates_train = train_data_combined.duplicated()\n",
    "\n",
    "print(\"Are there duplicate rows in the test datasets?\", duplicates_test.any())\n",
    "print(\"Are there duplicate rows in the train datasets?\", duplicates_train.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e701ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T20:10:26.600645Z",
     "start_time": "2023-06-27T20:10:26.595804Z"
    }
   },
   "outputs": [],
   "source": [
    "label_dict = {1: 'World', 2: 'Sports', 3: 'Business', 4: 'Science'}\n",
    "\n",
    "\n",
    "new_dataset_train['Class Index'] = new_dataset_train['Class Index'].map(label_dict)\n",
    "new_dataset_test['Class Index'] = new_dataset_test['Class Index'].map(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a157c74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T20:10:28.013089Z",
     "start_time": "2023-06-27T20:10:28.011037Z"
    }
   },
   "outputs": [],
   "source": [
    "train_updated = new_dataset_train\n",
    "test_updated = new_dataset_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf05d1e",
   "metadata": {},
   "source": [
    "## Training the model on the previous dataset (this is an updated news set with completely different rows) and then testing the model to predict a new dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657ecbdb",
   "metadata": {},
   "source": [
    "### Multiclass Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b29f4b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-27T20:14:56.843974Z",
     "start_time": "2023-06-27T20:13:06.587944Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def train_classifier(model_type):\n",
    "    X_train = agnews_train['text']\n",
    "    y_train = agnews_train['label_int']\n",
    "\n",
    "    # The ag news dataset we were given\n",
    "    X_test_init = agnews_test['text']\n",
    "    y_test_init = agnews_test['label_int']\n",
    "\n",
    "    # The downloaded dataset from Kaggle with new articles\n",
    "    X_test_new = new_dataset_test['Description']  \n",
    "    y_test_new = new_dataset_test['Class Index']  \n",
    "    \n",
    "    #We decided to use Tfidf with unigrams and bigrams\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "        \n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test_init = vectorizer.transform(X_test_init)\n",
    "    X_test_new = vectorizer.transform(X_test_new)\n",
    "\n",
    "    model = None\n",
    "    if model_type == 'NaiveBayes':\n",
    "        model = MultinomialNB()\n",
    "    elif model_type == 'LogisticRegression':\n",
    "        model = LogisticRegression(max_iter=1000, n_jobs=-1)\n",
    "    elif model_type == 'LinearSVC':\n",
    "        model = LinearSVC(dual=False, max_iter=1000)\n",
    "        \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Performance on initial agnews dataset (test)\n",
    "    predictions_init = model.predict(X_test_init)\n",
    "    print(f\"\\nClassification Report for {model_type} on initial test set with TfidfVectorizer:\")\n",
    "    print(classification_report(y_test_init, predictions_init))\n",
    "\n",
    "    # Performance on downloaded agnews dataset (test)\n",
    "    predictions_new = model.predict(X_test_new)\n",
    "    print(f\"\\nClassification Report for {model_type} on new test set with TfidfVectorizer:\")\n",
    "    print(classification_report(y_test_new, predictions_new))\n",
    "\n",
    "    #We try the 3 types of models we tried before\n",
    "for model_type in ['NaiveBayes', 'LogisticRegression', 'LinearSVC']:\n",
    "    train_classifier(model_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b45dad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "399.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
